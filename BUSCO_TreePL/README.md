# BUSCO phylogenetic tree and treePL dating 

This folder contains all the scripts used to generate the dated BUSCO phylogenetic tree (Figure 1).

## 1) Running BUSCO on each reference genome

The first step (busco.sh) involves finding and retrieving all the BUSCO genes/protein sequences for each of the 18 reference genomes used (hereafter referred to as $ref_genome). We ran the BUSCO software using default option:

``` bash
busco -m genome -i $ref_genome -l lepidoptera_odb10 -c 1 --config config.ini
```

## 2) Identify common genes to all species

- For each one of the 18 species we extract all the protein sequences generated by BUSCO using the following command:

``` bash
for i in Bicyclus_anynana Chetone_histrio Heliconius_erato Heliconius_numata Hypothyris_anastasia Mechanitis_mazaeus Melinaea_isocomma Melinaea_menophilus Plutella_xylostella Biston_betularia Danaus_plexippus Heliconius_melpomene Heliconius_pardalinus Ithomia_salapia Mechanitis_messenoides Melinaea_marsaeus Melinaea_mothone Tithorea_tarricina; do 
cd $i; ls *faa > ../"$i"_busco_gene.txt ; cd .. 
done
paste *txt > common_busco_genes.txt
```

- Then the genes common to all the species were determined using the R script common_genes.R like this

``` bash
Rscript $SCRIPT/common_genes.R common_busco_genes.txt
```

- Finally we used the command below to keep the fasta protein sequences and nucleotide sequences common to the 18 species
``` bash
[ -e concatanated_genes_prot ] && rm -r concatanated_genes_prot
[ -e concatanated_genes_nucl ] && rm -r concatanated_genes_nucl
mkdir -p concatanated_genes_prot concatanated_genes_nucl

for i in  Bicyclus_anynana Chetone_histrio  Heliconius_erato Heliconius_numata Hypothyris_anastasia Mechanitis_mazaeus Melinaea_isocomma Melinaea_menophilus Plutella_xylostella Biston_betularia Danaus_plexippus Heliconius_melpomene Heliconius_pardalinus Ithomia_salapia Mechanitis_messenoides Melinaea_marsaeus Melinaea_mothone Tithorea_tarricina; do cat common_genes.txt|perl -pe 's/\.faa//g'| while read line; do cat $i/$line*faa >> concatanated_genes_prot/$line.faa; cat $i/$line*fna >> concatanated_genes_nucl/$line.fna; done; done
```

## 2) SNP calling
The SNP calling was performed in several steps:

### Generate GVCF
The folder 2_gvcf contains the scripts that were used to obtain the GVCFs using GATK HaplotypeCaller. For the sake of speed, the script was applied to each genome and each genome interval.

``` bash
gatk --java-options "-Xmx4g" HaplotypeCaller \
-R $ref_genome \
-I sorted_dedup.bam \
-O ${SLURM_ARRAY_TASK_ID}.g.vcf.gz \
--intervals $intervals \
--output-mode EMIT_ALL_CONFIDENT_SITES \
-ERC GVCF \
--dont-use-soft-clipped-bases 
```
  
### Combine GVCFs
The folder 3_Combined_gvcf contains the scripts used to merge GVCFs of all samples of one species. We used the CombineGVCFs option of GATK for that end. For the sake of speed, the script was applied to each species and each genome interval.

``` bash
gatk --java-options -Xmx15g CombineGVCFs \
-R $ref_genome \
$variants \
-O intervals_merged_${SLURM_ARRAY_TASK_ID} \
-intervals $intervals
```

### Genotype the GVCFs
The folder 4_Genotype_gvcfs contains the scripts necessary to genotype the GVCFs and generate raw VCFs. It uses GenotypeGVCFs option of GATK. For the sake of speed, the script was applied to each species and each genome interval.

``` bash
gatk --java-options -Xmx15g GenotypeGVCFs \
-R $ref_genome \
-V intervals_merged_${SLURM_ARRAY_TASK_ID} \
-O genotypeGVCF.intervals_${SLURM_ARRAY_TASK_ID}.vcf.gz
-intervals $intervals
```
### Filter VCFs
The VCFs were further filtered using BCFtools. More precisely BCFtools was used to keep bi-allelic SNPs with a variant quality score of at least 10, a genotype quality of at least 10, a depth of coverage of at least 5 and to exclude any SNPs with more than 20% of missing data.

``` bash
bcftools filter -e 'FORMAT/DP < 1 |FORMAT/GQ < 5 |QUAL <= 5' --set-GTs . genotypeGVCF.intervals_${SLURM_ARRAY_TASK_ID}.vcf.gz -O u | bcftools view -U -i 'TYPE=="snp"' -m2 -M2 -v snps -O v| bcftools view -i 'F_MISSING < 0.2'> genotypeGVCF.intervals_${SLURM_ARRAY_TASK_ID}.filters.snps.vcf
```
### Combining all VCF intervals in a single VCF
We combined all 60 intervals to generate a single VCF for each species. Each VCF was also zipped (bgzip) and tabulated (tabix). 

``` bash
cat *intervals_0.* > snps.vcf
for j in {1..59}; do cat *intervals_"$j".*|grep -v '#' >> snps.vcf; done
bgzip -@ 12 snps.vcf && tabix -p vcf snps.vcf.gz
```

## 3) Phasing and missing data imputation
The phasing and the data imputation were done using ShapeIT with default option. Shape it was applied to each scaffold/chromosome separately. Each phased VCF was also zipped (bgzip) and tabulated (tabix). 

``` bash
SCAFFOLD=$(sed -n "${SLURM_ARRAY_TASK_ID}"p list_of_scaffolds.txt)
$SHAPEIT --input snps.vcf.gz --region $SCAFFOLD --output phased.snps.vcf
bgzip phased.snps.vcf && tabix -p vcf phased.snps.vcf.gz
```


